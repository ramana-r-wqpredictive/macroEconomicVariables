{"cells":[{"cell_type":"code","source":["%pip install -U data_utils\n%pip install mlflow\n%pip install -U catboost\n%pip install -U rbfopt\n%pip install -U prophet"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nLooking in indexes: https://pypi.org/simple, https://databricks:****@wqp.jfrog.io/artifactory/api/pypi/pypi/simple/\nRequirement already satisfied: data_utils in /databricks/python3/lib/python3.8/site-packages (2.2.8)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nLooking in indexes: https://pypi.org/simple, https://databricks:****@wqp.jfrog.io/artifactory/api/pypi/pypi/simple/\nRequirement already satisfied: mlflow in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (1.27.0)\nRequirement already satisfied: pytz in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2020.5)\nRequirement already satisfied: Flask in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.1.2)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.2)\nRequirement already satisfied: alembic in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (1.8.1)\nRequirement already satisfied: pandas in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: sqlparse&gt;=0.3.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.4.1)\nRequirement already satisfied: protobuf&gt;=3.12.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.17.2)\nRequirement already satisfied: gitpython&gt;=2.1.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.1.12)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (1.23.1)\nRequirement already satisfied: databricks-cli&gt;=0.8.7 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.14.3)\nRequirement already satisfied: packaging in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.9)\nRequirement already satisfied: requests&gt;=2.17.3 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (2.25.1)\nRequirement already satisfied: cloudpickle in /databricks/python3/lib/python3.8/site-packages (from mlflow) (1.6.0)\nRequirement already satisfied: click&gt;=7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (7.1.2)\nRequirement already satisfied: sqlalchemy&gt;=1.4.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (1.4.39)\nRequirement already satisfied: gunicorn in /databricks/python3/lib/python3.8/site-packages (from mlflow) (20.0.4)\nRequirement already satisfied: docker&gt;=4.0.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (5.0.3)\nRequirement already satisfied: querystring-parser in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (1.2.4)\nRequirement already satisfied: pyyaml&gt;=5.1 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (5.4.1)\nRequirement already satisfied: importlib-metadata!=4.7.0,&gt;=3.7.0 in /databricks/python3/lib/python3.8/site-packages (from mlflow) (3.10.0)\nRequirement already satisfied: entrypoints in /databricks/python3/lib/python3.8/site-packages (from mlflow) (0.3)\nRequirement already satisfied: prometheus-flask-exporter in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from mlflow) (0.20.2)\nRequirement already satisfied: six&gt;=1.10.0 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (1.15.0)\nRequirement already satisfied: tabulate&gt;=0.7.7 in /databricks/python3/lib/python3.8/site-packages (from databricks-cli&gt;=0.8.7-&gt;mlflow) (0.8.7)\nRequirement already satisfied: websocket-client&gt;=0.32.0 in /databricks/python3/lib/python3.8/site-packages (from docker&gt;=4.0.0-&gt;mlflow) (0.57.0)\nRequirement already satisfied: gitdb&lt;5,&gt;=4.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitpython&gt;=2.1.0-&gt;mlflow) (4.0.7)\nRequirement already satisfied: smmap&lt;5,&gt;=3.0.1 in /databricks/python3/lib/python3.8/site-packages (from gitdb&lt;5,&gt;=4.0.1-&gt;gitpython&gt;=2.1.0-&gt;mlflow) (3.0.5)\nRequirement already satisfied: zipp&gt;=0.5 in /databricks/python3/lib/python3.8/site-packages (from importlib-metadata!=4.7.0,&gt;=3.7.0-&gt;mlflow) (3.4.1)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2020.12.5)\nRequirement already satisfied: chardet&lt;5,&gt;=3.0.2 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (4.0.0)\nRequirement already satisfied: urllib3&lt;1.27,&gt;=1.21.1 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (1.25.11)\nRequirement already satisfied: idna&lt;3,&gt;=2.5 in /databricks/python3/lib/python3.8/site-packages (from requests&gt;=2.17.3-&gt;mlflow) (2.10)\nRequirement already satisfied: greenlet!=0.4.17 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from sqlalchemy&gt;=1.4.0-&gt;mlflow) (1.1.2)\nRequirement already satisfied: importlib-resources in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from alembic-&gt;mlflow) (5.9.0)\nRequirement already satisfied: Mako in /databricks/python3/lib/python3.8/site-packages (from alembic-&gt;mlflow) (1.1.3)\nRequirement already satisfied: Werkzeug&gt;=0.15 in /databricks/python3/lib/python3.8/site-packages (from Flask-&gt;mlflow) (1.0.1)\nRequirement already satisfied: Jinja2&gt;=2.10.1 in /databricks/python3/lib/python3.8/site-packages (from Flask-&gt;mlflow) (3.0.3)\nRequirement already satisfied: itsdangerous&gt;=0.24 in /databricks/python3/lib/python3.8/site-packages (from Flask-&gt;mlflow) (1.1.0)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /databricks/python3/lib/python3.8/site-packages (from Jinja2&gt;=2.10.1-&gt;Flask-&gt;mlflow) (2.1.1)\nRequirement already satisfied: setuptools&gt;=3.0 in /usr/local/lib/python3.8/dist-packages (from gunicorn-&gt;mlflow) (52.0.0)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /databricks/python3/lib/python3.8/site-packages (from packaging-&gt;mlflow) (2.4.7)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas-&gt;mlflow) (2.8.1)\nRequirement already satisfied: prometheus-client in /databricks/python3/lib/python3.8/site-packages (from prometheus-flask-exporter-&gt;mlflow) (0.10.1)\nCollecting numpy\n  Downloading https://wqp.jfrog.io/artifactory/api/pypi/pypi/packages/packages/2f/14/abc14a3f3663739e5d3c8fd980201d10788d75fea5b0685734227052c4f0/numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\nInstalling collected packages: numpy\n  Attempting uninstall: numpy\n    Found existing installation: numpy 1.23.1\n    Uninstalling numpy-1.23.1:\n      Successfully uninstalled numpy-1.23.1\nERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npetastorm 0.11.2 requires pyspark&gt;=2.1.0, which is not installed.\ntensorflow-cpu 2.6.0 requires numpy~=1.19.2, but you have numpy 1.22.4 which is incompatible.\nspark-df-profiling 1.1.15 requires numpy&lt;1.20.0,&gt;=1.14.1, but you have numpy 1.22.4 which is incompatible.\nnumba 0.54.0 requires numpy&lt;1.21,&gt;=1.17, but you have numpy 1.22.4 which is incompatible.\nSuccessfully installed numpy-1.22.4\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nLooking in indexes: https://pypi.org/simple, https://databricks:****@wqp.jfrog.io/artifactory/api/pypi/pypi/simple/\nRequirement already satisfied: catboost in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (1.0.6)\nRequirement already satisfied: plotly in /databricks/python3/lib/python3.8/site-packages (from catboost) (5.1.0)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from catboost) (1.15.0)\nRequirement already satisfied: matplotlib in /databricks/python3/lib/python3.8/site-packages (from catboost) (3.4.2)\nRequirement already satisfied: pandas&gt;=0.24.0 in /databricks/python3/lib/python3.8/site-packages (from catboost) (1.2.4)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from catboost) (1.6.2)\nRequirement already satisfied: graphviz in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from catboost) (0.20.1)\nRequirement already satisfied: numpy&gt;=1.16.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from catboost) (1.22.4)\nRequirement already satisfied: pytz&gt;=2017.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.24.0-&gt;catboost) (2020.5)\nRequirement already satisfied: python-dateutil&gt;=2.7.3 in /databricks/python3/lib/python3.8/site-packages (from pandas&gt;=0.24.0-&gt;catboost) (2.8.1)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib-&gt;catboost) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib-&gt;catboost) (0.10.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib-&gt;catboost) (8.2.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib-&gt;catboost) (2.4.7)\nRequirement already satisfied: tenacity&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from plotly-&gt;catboost) (6.2.0)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nLooking in indexes: https://pypi.org/simple, https://databricks:****@wqp.jfrog.io/artifactory/api/pypi/pypi/simple/\nRequirement already satisfied: rbfopt in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (4.2.4)\nRequirement already satisfied: numpy in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from rbfopt) (1.22.4)\nRequirement already satisfied: scipy in /databricks/python3/lib/python3.8/site-packages (from rbfopt) (1.6.2)\nRequirement already satisfied: pyomo in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from rbfopt) (6.4.1)\nRequirement already satisfied: ply in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from pyomo-&gt;rbfopt) (3.11)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\nPython interpreter will be restarted.\nLooking in indexes: https://pypi.org/simple, https://databricks:****@wqp.jfrog.io/artifactory/api/pypi/pypi/simple/\nRequirement already satisfied: prophet in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (1.1)\nRequirement already satisfied: matplotlib&gt;=2.0.0 in /databricks/python3/lib/python3.8/site-packages (from prophet) (3.4.2)\nRequirement already satisfied: setuptools-git&gt;=1.2 in /databricks/python3/lib/python3.8/site-packages (from prophet) (1.2)\nRequirement already satisfied: LunarCalendar&gt;=0.0.9 in /databricks/python3/lib/python3.8/site-packages (from prophet) (0.0.9)\nRequirement already satisfied: numpy&gt;=1.15.4 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from prophet) (1.22.4)\nRequirement already satisfied: convertdate&gt;=2.1.2 in /databricks/python3/lib/python3.8/site-packages (from prophet) (2.3.2)\nRequirement already satisfied: holidays&gt;=0.13 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from prophet) (0.14.2)\nRequirement already satisfied: pandas&gt;=1.0.4 in /databricks/python3/lib/python3.8/site-packages (from prophet) (1.2.4)\nRequirement already satisfied: setuptools&gt;=42 in /usr/local/lib/python3.8/dist-packages (from prophet) (52.0.0)\nRequirement already satisfied: wheel&gt;=0.37.0 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from prophet) (0.37.1)\nRequirement already satisfied: Cython&gt;=0.22 in /databricks/python3/lib/python3.8/site-packages (from prophet) (0.29.23)\nRequirement already satisfied: cmdstanpy&gt;=1.0.1 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/lib/python3.8/site-packages (from prophet) (1.0.4)\nRequirement already satisfied: tqdm&gt;=4.36.1 in /databricks/python3/lib/python3.8/site-packages (from prophet) (4.59.0)\nRequirement already satisfied: python-dateutil&gt;=2.8.0 in /databricks/python3/lib/python3.8/site-packages (from prophet) (2.8.1)\nRequirement already satisfied: ujson in /databricks/python3/lib/python3.8/site-packages (from cmdstanpy&gt;=1.0.1-&gt;prophet) (4.0.2)\nRequirement already satisfied: pytz&gt;=2014.10 in /databricks/python3/lib/python3.8/site-packages (from convertdate&gt;=2.1.2-&gt;prophet) (2020.5)\nRequirement already satisfied: pymeeus&lt;=1,&gt;=0.3.13 in /databricks/python3/lib/python3.8/site-packages (from convertdate&gt;=2.1.2-&gt;prophet) (0.5.11)\nRequirement already satisfied: hijri-converter in /databricks/python3/lib/python3.8/site-packages (from holidays&gt;=0.13-&gt;prophet) (2.2.1)\nRequirement already satisfied: korean-lunar-calendar in /databricks/python3/lib/python3.8/site-packages (from holidays&gt;=0.13-&gt;prophet) (0.2.1)\nRequirement already satisfied: ephem&gt;=3.7.5.3 in /databricks/python3/lib/python3.8/site-packages (from LunarCalendar&gt;=0.0.9-&gt;prophet) (4.0.0.2)\nRequirement already satisfied: kiwisolver&gt;=1.0.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (1.3.1)\nRequirement already satisfied: cycler&gt;=0.10 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (0.10.0)\nRequirement already satisfied: pillow&gt;=6.2.0 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (8.2.0)\nRequirement already satisfied: pyparsing&gt;=2.2.1 in /databricks/python3/lib/python3.8/site-packages (from matplotlib&gt;=2.0.0-&gt;prophet) (2.4.7)\nRequirement already satisfied: six in /databricks/python3/lib/python3.8/site-packages (from cycler&gt;=0.10-&gt;matplotlib&gt;=2.0.0-&gt;prophet) (1.15.0)\nWARNING: You are using pip version 21.0.1; however, version 22.2.1 is available.\nYou should consider upgrading via the &#39;/local_disk0/.ephemeral_nfs/envs/pythonEnv-f9fb2c67-dae8-4aee-91a6-1b5dd963aaef/bin/python -m pip install --upgrade pip&#39; command.\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":1},{"cell_type":"code","source":["from snowflake_client import SnowflakeClient\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport mlflow\nimport mlflow.pyfunc\nimport mlflow.sklearn\nfrom mlflow.models.signature import infer_signature\nfrom mlflow.utils.environment import _mlflow_conda_env\nimport cloudpickle\nimport time\nfrom databricks import koalas as ks\nfrom catboost import CatBoostRegressor\nfrom prophet import Prophet\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import current_date\nimport matplotlib.pyplot as plt\n# import pyspark.pandas as ps"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["client = SnowflakeClient('refined_spins')\npd.set_option('display.max_columns', 200)\npd.set_option('display.max_rows', None)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\nip_total_us = client.query(\"SELECT * FROM IMMUTA.REFINED_SPINS.ABT_SPINS \") #and UPC = '00-17800-12596'\n# WHERE MARKET_REGION = 'MARKET' AND market_region_name = 'PITTSBURGH, PA' and UPC ='00-17800-13483' \nip_pandas_total_us = ks.DataFrame(ip_total_us)\nip_pandas = ip_pandas_total_us\nip_pandas = ip_pandas[ip_pandas['BRAND'] != 'PRIVATE LABEL']\nip_pandas['SPPD'].fillna(0, inplace=True)\nip_pandas = ip_pandas[ip_pandas['SPPD'] > 0]"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["prod = client.table(\"ABT_SPINS_PRODUCTS\")\nprodPandas = prod.toPandas()\n\ndel prodPandas['MAIN_CATEGORY']\ndel prodPandas['SUBCATEGORY']\ndel prodPandas['BRAND']\ndel prodPandas['DESCRIPTION']"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/databricks/spark/python/pyspark/sql/pandas/utils.py:79: UserWarning: The conversion of DecimalType columns is inefficient and may take a long time. Column names: [PACK_COUNT] If those columns are not necessary, you may consider dropping them or converting to primitive types before the conversion.\n  warnings.warn(\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["class AlphaModel():\n    def __init__(self, TARGET, LEVEL):\n        # Example how to work with alpha's state:\n        # self.observed_states = []\n        # prod prep\n\n        self.TARGET = TARGET\n        self.LEVEL = LEVEL\n#         self.params ={'iterations': 2000 }\n        \n        ip = ip_pandas[ip_pandas['SPPD'] > 0]\n        ip['DISCOUNT_PERC'] = ip['DISCOUNT_PERC'].replace(np.nan, 0)\n        self.ip = ip.merge(ks.DataFrame(prodPandas), how=\"left\", on=['UPC'])\n        \n        #filtering the ip for the right level -- \n        if self.LEVEL == \"TOTAL US\":\n          self.ip = self.ip[self.ip['MARKET_REGION'] == 'TOTAL US']\n        elif self.LEVEL == \"MARKET\":\n          self.ip = self.ip[self.ip['MARKET_REGION'] == 'MARKET']\n        elif self.LEVEL == \"REGION\":\n          self.ip = self.ip[self.ip['MARKET_REGION'] == 'REGION']   \n        \n        prod = prodPandas.filter(\n            ['UPC', 'PRODUCT_TYPE', 'POSITIONING_GROUP', 'LABELED_ORGANIC', 'SUBCATEGORY','BRAND', \n             'COMPANY',  'UNIT_OF_MEASURE',  'PACKAGING_TYPE_PRIMARY', 'FORM', 'LABELED_NON_GMO', \n             'STORAGE', 'PACK_COUNT'])\n        self.prod = prod\n\n        \n\n        # MERGING PRODUCT ATTRIBUTES\n \n        self.ip['UPC'].fillna(0, inplace=True)     \n        self.ip['C19_NYCASES'] = self.ip['C19_NYCASES'].fillna(value=0)\n        self.ip['C19_NYCASES'] = self.ip['C19_NYCASES'].astype(float)\n        self.ip['C19_DEATHS'] = self.ip['C19_DEATHS'].fillna(value=0)\n        self.ip['C19_DEATHS'] = self.ip['C19_DEATHS'].astype(float) \n        self.ip['INITIAL_CLAIMS'] = self.ip['INITIAL_CLAIMS'].fillna(value=0)\n        self.ip['INITIAL_CLAIMS'] = self.ip['INITIAL_CLAIMS'].astype(float)\n        self.ip['TIMEPERIODENDDATE'] = ks.to_datetime(self.ip['TIMEPERIODENDDATE'])\n        self.ip['WEEK']=self.ip['TIMEPERIODENDDATE'].dt.week\n        self.ip['WEEK'] = self.ip['WEEK'].astype(int)\n        self.ip['MONTH']=self.ip['TIMEPERIODENDDATE'].dt.month\n        self.ip['MONTH'] = self.ip['MONTH'].astype(int)\n        self.ip['YEAR']=self.ip['TIMEPERIODENDDATE'].dt.year\n        self.ip['YEAR'] = self.ip['YEAR'].astype(int)\n        \n                 \n         \n        week_count= self.ip.groupby(by=['MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC'],as_index=False)[\"WEEK\"].count()\n        week_count.rename(columns = {'WEEK':'WEEK_COUNT'}, inplace = True)\n        \n        self.ip=self.ip.merge(week_count,on=['MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC'],how='left')\n \n        self.ip = self.ip[self.ip['WEEK_COUNT'] > 12]\n        \n\n     \n        print(f\"reading prophet inputs for {self.LEVEL}\")\n        #load relevant file - for training\n        if self.LEVEL == \"TOTAL US\":\n          forecast=ks.DataFrame(client.table('carina_prophet_features_TOTALUS_deploy'))\n        elif self.LEVEL == \"MARKET\":\n          forecast=ks.DataFrame(client.table('carina_prophet_features_MARKET_deploy'))\n        elif self.LEVEL == \"REGION\":\n          forecast=ks.DataFrame(client.table('carina_prophet_features_REGION_deploy'))\n    \n        forecast=forecast.filter(items=['TIMEPERIODENDDATE','YHAT','MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC','MIN_SPPD','MAX_SPPD'])\n\n\n        \n        forecast=forecast.set_index(['MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC','TIMEPERIODENDDATE'])\n        self.ip=self.ip.set_index(['MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC','TIMEPERIODENDDATE'])\n        \n       \n\n\n        \n\n        print(self.ip.shape)\n        self.ip = ks.merge(self.ip,forecast, left_index=True, right_index=True,how='left')   \n        print(self.ip.shape)    \n\n        #self.ip=self.ip.to_pandas()\n  \n        \n        #fro deployment there is not testing - so everything goes in \n        \n         \n\n          \n    def fit(self):\n\n        cats = ['UPC',  'PRODUCT_TYPE', 'POSITIONING_GROUP', 'LABELED_ORGANIC', 'SUBCATEGORY','BRAND', \n                 'COMPANY',  'UNIT_OF_MEASURE',  'PACKAGING_TYPE_PRIMARY', 'FORM', 'LABELED_NON_GMO', \n                'STORAGE', 'PACK_COUNT', 'MARKET_REGION_NAME', 'MARKET_REGION','CHANNEL']\n        self.cats = cats\n        self.cols_prophet = ['UPC', 'BASE_PRICE', 'DISCOUNT_PERC', 'AVGPCTACV', 'AVGPCTACVDISPLAYONLY',\n                    'AVGPCTACVFEATUREONLY','AVGPCTACVFEATUREANDDISPLAY', 'AVGPCTACVTPR', 'C19_NYCASES', \n                             'C19_DEATHS', 'INITIAL_CLAIMS', 'PACK_COUNT',  'PRODUCT_TYPE', 'POSITIONING_GROUP',\n                             'LABELED_ORGANIC', 'SUBCATEGORY', 'BRAND', 'COMPANY',  'UNIT_OF_MEASURE',  \n                             'PACKAGING_TYPE_PRIMARY', 'FORM', 'LABELED_NON_GMO', 'STORAGE',                 \n                     'MARKET_REGION_NAME', 'MARKET_REGION','CHANNEL', 'YHAT', 'INFLATION_RATE_ALL_ITEMS']\n        \n        print(\"max dATE for training\")\n\n        self.ip=self.ip.to_pandas().reset_index()\n        #self.ip['DISCOUNT_PERC']=self.ip['DISCOUNT_PERC'].fillna(0)\n        #self.ip['DISCOUNT_PERC']=np.where(self.ip['DISCOUNT_PERC']<0,0,self.ip['DISCOUNT_PERC'])\n        #self.ip['AVGPCTACVTPR']=np.where(self.ip['DISCOUNT_PERC']<=0,0,self.ip['AVGPCTACVTPR'])          \n        self.ip['YHAT']=np.where(self.ip['YHAT']<0,self.ip['MIN_SPPD'],self.ip['YHAT'])\n        self.ip['DISCOUNT_PERC']=self.ip['DISCOUNT_PERC'].fillna(0)\n        self.ip['DISCOUNT_PERC']=np.where(self.ip['DISCOUNT_PERC']<0,0,self.ip['DISCOUNT_PERC'])\n        self.ip['AVGPCTACVTPR']=np.where(self.ip['DISCOUNT_PERC']<=0,0,self.ip['AVGPCTACVTPR'])  \n        #print(self.ip.TIMEPERIODENDDATE.max())\n\n                \n        Y = np.log(self.ip[self.TARGET])\n        self.y = Y\n        \n        \n        self.X_prophet = self.ip.filter(items=self.cols_prophet)\n        self.X_prophet.fillna(0, inplace =True)\n        for c in self.X_prophet.columns:\n            col_type = self.X_prophet[c].dtype\n            if col_type == 'object' or col_type.name == 'category':\n                self.X_prophet[c] = self.X_prophet[c].astype('category')\n            \n            \n\n        self.cat_features = cats\n        print(\"model start\")\n        print(\"cats:\", cats)\n        print(\"self.X_prophet\", self.X_prophet.columns)\n        print(\"self.ip\", self.ip.columns)\n        self.model_base = CatBoostRegressor(cat_features= cats,\n                               loss_function='MAPE',verbose=True)        \n        self.model_base.fit(self.X_prophet, Y)      \n        print(\"model end\")\n        \n        #comment for deployment --- not required. \n     #   self.feature_importance_df=pd.DataFrame({\"variable\":self.model_base.feature_names_, \"importance\":self.model_base.feature_importances_})\n        \n      #  client.save(spark.createDataFrame(self.feature_importance_df), 'CARINA_REGION_featureImportance', 'OVERWRITE')\n       \n    #    print(self.feature_importance_df)"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["def predict(model, input_data, attributes):\n    test = input_data.copy()\n    prod = attributes\n\n\n    #taking only required inputs for pred call --\n   \n\n    ## adding month year variables\n    test['TIMEPERIODENDDATE'] = pd.to_datetime(test['TIMEPERIODENDDATE'], format = \"%Y/%m/%d\")\n#     test['WEEK']= test['TIMEPERIODENDDATE'].dt.isocalendar().week\n#     test['WEEK'] = test['WEEK'].astype(int)\n#     test['MONTH']= test['TIMEPERIODENDDATE'].dt.month\n#     test['MONTH'] = test['MONTH'].astype(int)\n#     test['YEAR'] = test['TIMEPERIODENDDATE'].dt.year\n#     test['YEAR'] = test['YEAR'].astype(int)\n    \n  \n\n    #ADDING PRODUCT ATTRIBUTES\n\n    prod = prod.filter(\n      ['UPC', 'PRODUCT_TYPE', 'POSITIONING_GROUP', 'LABELED_ORGANIC',\n       'COMPANY',  'UNIT_OF_MEASURE',  'PACKAGING_TYPE_PRIMARY', 'FORM', 'LABELED_NON_GMO',\n       'STORAGE', 'PACK_COUNT'])\n\n\n\n    test = test.merge(prod, how=\"left\", on=['UPC'])\n\n    #DATA IMPUTAIONS DONE IN THE TRAINING DATA\n    test['C19_NYCASES'] = test['C19_NYCASES'].fillna(value=0)\n    test['C19_NYCASES'] = test['C19_NYCASES'].astype(float)\n    test['C19_DEATHS'] = test['C19_DEATHS'].fillna(value=0)\n    test['C19_DEATHS'] = test['C19_DEATHS'].astype(float)\n    test['INITIAL_CLAIMS'] = test['INITIAL_CLAIMS'].fillna(value=0)\n    test['INITIAL_CLAIMS'] = test['INITIAL_CLAIMS'].astype(float)\n    test['DISCOUNT_PERC'] = test['DISCOUNT_PERC'].replace(np.nan, 0)\n    test['PACK_COUNT'] = test['PACK_COUNT'].astype(str)\n    test.fillna(value=np.nan, inplace=True)\n    test.fillna(0, inplace=True)\n\n    for c in test.columns:\n        col_type = test[c].dtype\n        if col_type == 'object' or col_type.name == 'category':\n            test[c] = test[c].astype('category')\n\n    test['DISCOUNT_PERC']=test['DISCOUNT_PERC'].fillna(0)\n    test['DISCOUNT_PERC']=np.where(test['DISCOUNT_PERC']<0,0,test['DISCOUNT_PERC'])\n    test['AVGPCTACVTPR']=np.where(test['DISCOUNT_PERC']<=0,0,test['AVGPCTACVTPR'])    \n    \n    test = test.filter(items=['UPC', 'BASE_PRICE', 'DISCOUNT_PERC', 'AVGPCTACV', 'AVGPCTACVDISPLAYONLY',\n                    'AVGPCTACVFEATUREONLY','AVGPCTACVFEATUREANDDISPLAY', 'AVGPCTACVTPR', 'C19_NYCASES', \n                             'C19_DEATHS', 'INITIAL_CLAIMS', 'PACK_COUNT',  'PRODUCT_TYPE', 'POSITIONING_GROUP',\n                             'LABELED_ORGANIC', 'SUBCATEGORY', 'BRAND', 'COMPANY',  'UNIT_OF_MEASURE',  \n                             'PACKAGING_TYPE_PRIMARY', 'FORM', 'LABELED_NON_GMO', 'STORAGE',                 \n                     'MARKET_REGION_NAME', 'MARKET_REGION','CHANNEL', 'YHAT', 'INFLATION_RATE_ALL_ITEMS','MIN_SPPD'])\n\n            \n    pred = (model.predict(test))\n    \n    test['pred'] = np.exp(pred)\n#     test['pred_1'] = np.exp(pred)\n\n    #adding boundaries --\n\n    test['pred']=np.where(test.pred<0,test['MIN_SPPD'],test.pred)\n    #test['pred']=np.where(test.pred>test['MAX_SPPD'],test['MAX_SPPD'],test.pred)\n    #test['pred']=np.where(test.pred<test['MIN_SPPD']*0.5,test['YHAT'],test.pred)\n    test['pred']=np.where(test.AVGPCTACV==0,0,test.pred)\n    test['pred']=np.where(test.pred<0,test['MIN_SPPD'],test.pred)\n\n\n  \n\n\n#       test['SPPD_PRED'] = test['pred']\n#       test['SPPD_ACTUAL'] = test['SPPD']\n\n#       deployment_output = test[['SUBCATEGORY','CHANNEL','MARKET_REGION_NAME','MARKET_REGION','UPC','BASE_PRICE','DISCOUNT_PERC',\n#                                 'TIMEPERIODENDDATE', 'AVGPCTACV', 'SPPD_PRED', 'SPPD_ACTUAL', 'BRAND','YHAT']]\n#       print(deployment_output.head())\n#       client.save(spark.createDataFrame(deployment_output), 'CARINA_DEPLOYMENT_TOTALUS_allTrainingDeployTest', 'OVERWRITE')\n\n    return test['pred'].values\n\n\n\n#['TOTAL US', 'MARKET', 'REGION']\nfrom data_utils.model import log_predict\nfor level in ['TOTAL US', 'MARKET', 'REGION']:\n  model = AlphaModel('SPPD', level)\n  model.fit()    \n  model = model.model_base\n  level = level.replace(' ', '')\n  mlflow.set_experiment(f'/spins/baseline_model_{level}_sp')\n  feature_importance_df=pd.DataFrame({\"variable\":model.feature_names_, \"importance\":model.feature_importances_})\n  feature_importance_df.to_csv(\"/feature_importance_df.csv\")\n  \n#   prophet = client.table(f\"carina_prophet_features_{level}_deploy\").filter(\"year(TIMEPERIODENDDATE) == 2022\").toPandas()\n  attributes = client.table(\"ABT_SPINS_PRODUCTS\").toPandas()\n  with mlflow.start_run(run_name=f'spins_refresh_baseline_model_{level}'):\n    log_predict(predict, model, mlflow.catboost, artifacts={'attributes': attributes}, registered_model_name=f\"spins_baseline_model_{level}_sp\")\n    mlflow.log_artifact(\"/feature_importance_df.csv\")\n\n\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\nError while obtaining a new communication channel"]}}],"execution_count":7},{"cell_type":"code","source":["# #need to finalize the form - its a attribute getting generated in the _init_ call.\n\n\n\n# #comment for deploy -- \n# # prophet = client.table(\"carina_prophet_features_TOTALUS_deploy\").toPandas()\n\n# #ip_pandas should be predict call -- model_base_totalUS is the same model as called--- \n\n# ip_pandas = ip_pandas[ip_pandas['MARKET_REGION'] == 'TOTAL US'].toPandas()\n# ip_pandas['WEEK_COUNT'] = ip_pandas.groupby(['MARKET_REGION','MARKET_REGION_NAME','CHANNEL','UPC'])['WEEK'].transform('count')\n# ip_pandas = ip_pandas[ip_pandas['WEEK_COUNT'] > 12]\n\n\n# #make sure the model is always the same -- \n# #commenting the pred call for generating the var importance - but need this for deployment ---- \n\n# y_pred = predict(model_base_totalUS, ip_pandas, prodPandas, prophet)\n"],"metadata":{},"outputs":[{"output_type":"display_data","metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":8}],"metadata":{"name":"carina_model_inference_v5_forDeployment_test","notebookId":1095009},"nbformat":4,"nbformat_minor":0}